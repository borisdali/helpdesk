# Model configuration (required)
# Supported vendors: anthropic, gemini (or google)
HELPDESK_MODEL_VENDOR=anthropic
HELPDESK_API_KEY=<your-api-key-here>

# Model names by vendor (pick ONE):
#
# Anthropic models:
#   claude-haiku-4-5-20251001   - Fast, cost-effective
#   claude-sonnet-4-20250514    - Balanced performance
#   claude-opus-4-5-20251101    - Most capable
HELPDESK_MODEL_NAME=claude-haiku-4-5-20251001
#
# Gemini models (require function calling support):
#   gemini-2.5-flash            - Fast, recommended for most use cases
#   gemini-2.5-flash-lite       - Fastest, lower cost
#   gemini-2.5-pro              - Most capable 2.5 model
#   gemini-3-flash-preview      - Latest 3.0 series, fast
#   gemini-3-pro-preview        - Latest 3.0 series, most capable
# HELPDESK_MODEL_NAME=gemini-2.5-flash
#
# Note: Gemini 1.x and 2.0 models are retired and will return errors.

# Kubeconfig path for K8s and incident agents (optional)
KUBECONFIG=~/.kube/config

# Infrastructure inventory for the orchestrator (optional).
# Path to a JSON file describing your database servers, K8s clusters, and VMs.
# Copy the example and edit it with your real servers:
#   cp infrastructure.json.example infrastructure.json
HELPDESK_INFRA_CONFIG=./infrastructure.json

# Streaming mode for the orchestrator REPL (optional).
# "none" = disabled (default, works around ADK REPL bug in containers)
# "sse"  = enabled (streaming responses)
HELPDESK_STREAMING_MODE=none
